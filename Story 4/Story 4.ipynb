{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal \n",
    "\n",
    "# dash where the first page is just avg. it's be KDE with overlap\n",
    "#options are states\n",
    "\n",
    "# source: https://www.kaggle.com/datasets/thedevastator/jobs-dataset-from-glassdoor/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                  Job Title              Salary Estimate  \\\n",
      "0           0             Data Scientist   $53K-$91K (Glassdoor est.)   \n",
      "1           1  Healthcare Data Scientist  $63K-$112K (Glassdoor est.)   \n",
      "2           2             Data Scientist   $80K-$90K (Glassdoor est.)   \n",
      "3           3             Data Scientist   $56K-$97K (Glassdoor est.)   \n",
      "4           4             Data Scientist  $86K-$143K (Glassdoor est.)   \n",
      "\n",
      "                                     Job Description  Rating  \\\n",
      "0  Data Scientist\\nLocation: Albuquerque, NM\\nEdu...     3.8   \n",
      "1  What You Will Do:\\n\\nI. General Summary\\n\\nThe...     3.4   \n",
      "2  KnowBe4, Inc. is a high growth information sec...     4.8   \n",
      "3  *Organization and Job ID**\\nJob ID: 310709\\n\\n...     3.8   \n",
      "4  Data Scientist\\nAffinity Solutions / Marketing...     2.9   \n",
      "\n",
      "                                 Company Name         Location  \\\n",
      "0                      Tecolote Research\\n3.8  Albuquerque, NM   \n",
      "1  University of Maryland Medical System\\n3.4    Linthicum, MD   \n",
      "2                                KnowBe4\\n4.8   Clearwater, FL   \n",
      "3                                   PNNL\\n3.8     Richland, WA   \n",
      "4                     Affinity Solutions\\n2.9     New York, NY   \n",
      "\n",
      "     Headquarters                    Size  Founded  ... age python_yn R_yn  \\\n",
      "0      Goleta, CA   501 to 1000 employees     1973  ...  47         1    0   \n",
      "1   Baltimore, MD        10000+ employees     1984  ...  36         1    0   \n",
      "2  Clearwater, FL   501 to 1000 employees     2010  ...  10         1    0   \n",
      "3    Richland, WA  1001 to 5000 employees     1965  ...  55         1    0   \n",
      "4    New York, NY     51 to 200 employees     1998  ...  22         1    0   \n",
      "\n",
      "  spark aws  excel        job_simp  seniority  desc_len  num_comp  \n",
      "0     0   0      1  data scientist         na      2536         0  \n",
      "1     0   0      0  data scientist         na      4783         0  \n",
      "2     1   0      1  data scientist         na      3461         0  \n",
      "3     0   0      0  data scientist         na      3883         3  \n",
      "4     0   0      1  data scientist         na      2728         3  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "(742, 33)\n",
      "       Unnamed: 0      Rating      Founded      hourly  employer_provided  \\\n",
      "count  742.000000  742.000000   742.000000  742.000000         742.000000   \n",
      "mean   370.500000    3.618868  1837.154987    0.032345           0.022911   \n",
      "std    214.341239    0.801210   497.183763    0.177034           0.149721   \n",
      "min      0.000000   -1.000000    -1.000000    0.000000           0.000000   \n",
      "25%    185.250000    3.300000  1939.000000    0.000000           0.000000   \n",
      "50%    370.500000    3.700000  1988.000000    0.000000           0.000000   \n",
      "75%    555.750000    4.000000  2007.000000    0.000000           0.000000   \n",
      "max    741.000000    5.000000  2019.000000    1.000000           1.000000   \n",
      "\n",
      "       min_salary  max_salary  avg_salary  same_state         age   python_yn  \\\n",
      "count  742.000000  742.000000  742.000000  742.000000  742.000000  742.000000   \n",
      "mean    74.719677  128.149596  100.626011    0.557951   46.591644    0.528302   \n",
      "std     30.980593   45.220324   38.855948    0.496965   53.778815    0.499535   \n",
      "min     15.000000   16.000000   13.500000    0.000000   -1.000000    0.000000   \n",
      "25%     52.000000   96.000000   73.500000    0.000000   11.000000    0.000000   \n",
      "50%     69.500000  124.000000   97.500000    1.000000   24.000000    1.000000   \n",
      "75%     91.000000  155.000000  122.500000    1.000000   59.000000    1.000000   \n",
      "max    202.000000  306.000000  254.000000    1.000000  276.000000    1.000000   \n",
      "\n",
      "             R_yn       spark         aws       excel      desc_len  \\\n",
      "count  742.000000  742.000000  742.000000  742.000000    742.000000   \n",
      "mean     0.002695    0.225067    0.237197    0.522911   3869.545822   \n",
      "std      0.051882    0.417908    0.425651    0.499812   1521.495868   \n",
      "min      0.000000    0.000000    0.000000    0.000000    407.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000   2801.000000   \n",
      "50%      0.000000    0.000000    0.000000    1.000000   3731.000000   \n",
      "75%      0.000000    0.000000    0.000000    1.000000   4740.000000   \n",
      "max      1.000000    1.000000    1.000000    1.000000  10051.000000   \n",
      "\n",
      "         num_comp  \n",
      "count  742.000000  \n",
      "mean     1.053908  \n",
      "std      1.384239  \n",
      "min      0.000000  \n",
      "25%      0.000000  \n",
      "50%      0.000000  \n",
      "75%      3.000000  \n",
      "max      4.000000  \n",
      "['data scientist' 'na' 'analyst' 'data engineer' 'director' 'manager'\n",
      " 'mle']\n",
      "['NM' 'MD' 'FL' 'WA' 'NY' 'TX' 'CA' 'VA' 'MA' 'NJ' 'CO' 'IL' 'KY' 'OR'\n",
      " 'CT' 'MI' 'DC' 'OH' 'AL' 'MO' 'PA' 'GA' 'IN' 'LA' 'WI' 'NC' 'AZ' 'NE'\n",
      " 'MN' 'UT' 'TN' 'DE' 'ID' 'RI' 'IA' 'SC' 'KS']\n",
      "Unnamed: 0           0\n",
      "Job Title            0\n",
      "Salary Estimate      0\n",
      "Job Description      0\n",
      "Rating               0\n",
      "Company Name         0\n",
      "Location             0\n",
      "Headquarters         0\n",
      "Size                 0\n",
      "Founded              0\n",
      "Type of ownership    0\n",
      "Industry             0\n",
      "Sector               0\n",
      "Revenue              0\n",
      "Competitors          0\n",
      "hourly               0\n",
      "employer_provided    0\n",
      "min_salary           0\n",
      "max_salary           0\n",
      "avg_salary           0\n",
      "company_txt          0\n",
      "job_state            0\n",
      "same_state           0\n",
      "age                  0\n",
      "python_yn            0\n",
      "R_yn                 0\n",
      "spark                0\n",
      "aws                  0\n",
      "excel                0\n",
      "job_simp             0\n",
      "seniority            0\n",
      "desc_len             0\n",
      "num_comp             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/gsteinmetzsilber/DATA-608/main/Story%204/glassdoor_salary_data.csv\") \n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "print(df.describe())\n",
    "print(df[\"job_simp\"].unique()) \n",
    "print(df[\"job_state\"].unique()) #not all 50 states, that's okay there's a lot\n",
    "\n",
    "\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/28/xsh6qgd908q5ng87yxcxs6300000gn/T/ipykernel_43206/1892577531.py:11: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's only keep 4 roles:\n",
    "\n",
    "titles = [\"analyst\", \"data engineer\", \"data scientist\", \"mle\"]\n",
    "df_filtered = df[df[\"job_simp\"].isin(titles)]\n",
    "\n",
    "#while cleaning, let's just get the titles in better shape\n",
    "df_filtered.loc[:, \"job_simp\"] = df_filtered[\"job_simp\"].replace(\"mle\", \"Machine Learning Engineer\")\n",
    "df_filtered.loc[:, \"job_simp\"] = df_filtered[\"job_simp\"].str.title()\n",
    "\n",
    "# and order by state to make the later dropdown menu better\n",
    "df_filtered.sort_values(\"job_state\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x12617e690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "import plotly.graph_objects as go \n",
    "from scipy.stats import gaussian_kde \n",
    "\n",
    "# a bunch of the states don't have a lot of data / very low variance; both make plots look terrible. I define a function for determining whether there's enough quality data: \n",
    "def state_has_valid_data(state, df, job_roles, min_variance=0.01, min_records=3):\n",
    "    df_state = df[df[\"job_state\"] == state]\n",
    "    valid_job_roles_count = 0 #start counter\n",
    "\n",
    "    for job_role in job_roles:\n",
    "        job_df = df_state[df_state[\"job_simp\"] == job_role]\n",
    "        if len(job_df) >= min_records and job_df[\"avg_salary\"].var() >= min_variance: # Now a further check that there's more than one role to plot...otherwise it's not illuminating\n",
    "            valid_job_roles_count += 1  \n",
    "    \n",
    "    if valid_job_roles_count > 1:\n",
    "        return True  \n",
    "    return False\n",
    "\n",
    "job_roles = df_filtered[\"job_simp\"].unique() #unique roles\n",
    "valid_states = [state for state in df_filtered[\"job_state\"].unique() if state_has_valid_data(state, df_filtered, job_roles)]\n",
    "\n",
    "# Setting up Dash app\n",
    "app = Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Salary Distributions for Data-Related Jobs\"), #title\n",
    "    dcc.Dropdown(\n",
    "        id=\"state_dropdown\",\n",
    "        options=[{\"label\": \"All States\", \"value\": \"All\"}] + [{\"label\": state, \"value\": state} for state in valid_states],\n",
    "        value=\"All States\", #default\n",
    "        clearable=False,\n",
    "    ),\n",
    "    dcc.Graph(id=\"kde\")\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"kde\", \"figure\"), #the figure identified by kde changes when...\n",
    "    [Input(\"state_dropdown\", \"value\")] # the value of the state changes\n",
    ")\n",
    "def update_graph(selected_state):\n",
    "    df_plot = df_filtered[df_filtered[\"job_state\"] == selected_state] if selected_state != \"All States\" else df_filtered #unless we're looking at all states, filter to only look at the relevant state's rows\n",
    "    fig = go.Figure() #empty Plotly figure\n",
    "\n",
    "    # Create a trace for each job role even if it's not present in the current state to standardize the legend\n",
    "    for job_role in job_roles:\n",
    "        job_df = df_plot[df_plot[\"job_simp\"] == job_role] #filtering again to only look at one job type at a time\n",
    "\n",
    "        if not job_df.empty and job_df[\"avg_salary\"].var() >= 0.01:\n",
    "            try:\n",
    "                x = np.linspace(job_df[\"avg_salary\"].min(), job_df[\"avg_salary\"].max(), 200) #an array of 200 points btwn the min and max\n",
    "                kde = gaussian_kde(job_df[\"avg_salary\"]) #calculate the KDE\n",
    "                y = kde(x)\n",
    "                fig.add_trace(go.Scatter(x=x, y=y, fill=\"tozeroy\", name=job_role)) #add KDE at scatterplot and FILL\n",
    "            except Exception as e:\n",
    "                print(f\"Error with {job_role} in {selected_state}: {e}\")\n",
    "\n",
    "    # layout\n",
    "    fig.update_layout(legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1), #horizontal legend, outside plot area\n",
    "                      title_text=f\"Salary KDE Plot for {selected_state}\",\n",
    "                      xaxis_title=\"Salary (in $000s)\",\n",
    "                      yaxis_title=\"Density\",\n",
    "                      showlegend=True)\n",
    "\n",
    "    # Initially the legend wouldn't be consistent across the states, adding a dummy trace gets around this problem      \n",
    "    if len(fig.data) == 0:\n",
    "        for job_role in job_roles:\n",
    "            fig.add_trace(go.Scatter(x=[None], y=[None], mode=\"lines\", name=job_role))\n",
    "\n",
    "    return fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
